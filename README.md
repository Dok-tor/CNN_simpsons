# CNN_simpsons
Проект создания сверточной нейросети для соревнований на kaggle

Ссылка на соревнование Kaggle

Датасет можно скачать по ссылке https://drive.google.com/file/d/1woAe2CCvqLbXcoH89REjqPUrR6C5lSBY/view?usp=sharing

Изначально участие в этом соревновании предполагалось в рамках прохождения курса Deep Learning School от МФТИ.
Но позднее мне захотелось детально во всём разобраться и с абсолютного нуля написать и протестировать архитектуру нейросети,
а также провести операции с данными которые были доступны.

Проект можно поделить на 2 этапа:
1) Загрузка и способы расширения данных
2) Конструирование и эксперементы с архитектурами нейросетей.

Загрузка

Первые же попытки загрузить датасет показали, что данные неравномерно распределены по классам
в каких-то классах картинок более 1000, а в каких то всего 3.
Я опробовал несколько способов борьбы с этой проблемой
Вначале я просто дублировал картинки в "дефицитных" классах, чтобы их было больше 800. Это дало катострофическое снижение точности
по сравнению со случаем, в котором я ничего не делал.

Второй подход -- довести количество картинок в каждом классе до 100 а излишки убрать, в итоге в каждом классе должно было быть около 100 картинок
Оставшиеся картинки из других классов предполагалось подавать на вход при следующей итерации обучения, те же классы, в которых картинок изначально было меньше 100 
я скопировал и применил к ним случайные аугментации. В итоге после первой партии из 100 картинок на вход подавался датасет частично из новых и частично из страрых аугментированных.
Этот подход показал чуть лучшие результаты чем первый, но всё ещё не был выигрышным по сравнению с базовым, предполагающим отсутствие какой-либо работы с данными.

Последний подход, опробованный мной заключался также в доведении до минимум 100 картинок на класс путём копирования и дополнении всего получившегося датасета
таким же перевёрнутым по горизонтали и вертикали. Такой подход показал наилучший результат, причём вертикальное отражение существенно не повлияло на результат.

Построение и исследование нейросети
За основу мной был взят условный AlexNet, свои эксперементы я проводил изменяя все доступные параметры, добавляя и убирая слои.
В начале каждой следующей архитектуре я старался давать осмысленные названия, отражающие их основные отличия от предыдущей версии,
но потом моя фантазия закончилась и я стал "нумеровать" их буквами греческого алфавита, свои эксперементы завершил на букве "мю".
Подводя итог эксперементам, можно сказать, что наибольшую точность удалось достичь применяя не слишком массивную полносвязную часть, с небольшим количеством весов
и подбирая свёрточную часть так, чтобы на выходе неё и соответственно на входе линейной части было не более 5000 нейронов. Если нейронов больше, то нейросеть становилась склонна
к переобучению. Повысить результативность удалось активно применяя dropout в линейной части.
Функция активации ReLU была заменена мной на ELU после эксперементов, доказавших большую эффективность последней.

В качестве функции потерь использовал CrossEntropy, optimizer-ом выступал Adam, позже я заменил его на более свежий AdamW, но прироста точности не заметил.
Я пробовал использовать другие оптимизаторы и функции потерь, но это очень сильно просаживало точность, так что я отказался от этой идеи.

С самого начала я не мудрствуя лукаво оптимизировал точность(accuracy) т.к. ещё не разобрался с целевой метрикой f1, справедливо рассудив, что повышение общей точности вызовет
повышение целевой метрики. Потом я не стал менять, проверяя f1 через раз, и убеждаясь, что её значение увеличивается.

Под самый конец эксперементов я анализировал распознавание моделью каждого класса и мне пришла идея ансамбля моделей, каждая из которых будет бинарно разделять один класс от всех остальных,
я протестировал бинарный вариант лучшей своей модели, и пришёл к выводу, что такой подход имеет право на жизнь, но требуется очень большая оптимизация, сравнимая с той,
которая была проведена по оптимизации общей модели и работа, которую предстоит проделать, чтобы добиться такой же точности в данный момент нецелесообразна.
Но я оставил кусок кода, относящийся к этому подходу, для того чтобы потом возможно использовать его где-то ещё.

На настоящий момент на тестовых данных моя лучшая модель имеет показатель 0.98 по метрике f1.
Я считаю это удовлетворительным результатом.
